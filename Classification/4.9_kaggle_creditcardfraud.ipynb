{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# %matplotlib inline\n",
    "\n",
    "card_df = pd.read_csv(\"creditcard.csv\")\n",
    "print(card_df.head())\n",
    "\n",
    "# 인자로 입력받은 DataFrame을 복사한 뒤 Time 칼럼만 삭제하고 복사된 DataFrame 반환\n",
    "def get_preprocessed_df(df=None):\n",
    "    df_copy = df.copy()\n",
    "    df_copy.drop('Time', axis=1, inplace=True)\n",
    "    return df_copy\n",
    "\n",
    "# 사전 데이터 가공 후 학습과 데스트 데이터 세트를 반환하는 함수.\n",
    "def get_train_test_dataset(df=None):\n",
    "    # 인자로 입력된 DataFrame의 사전 데이터 사공이 완료된 복사 DataFrame 반환\n",
    "    df_copy = get_preprocessed_df(df)\n",
    "    # DataFrame의 맨 마지막 칼럼이 레이블, 나머지는 피처들\n",
    "    X_features = df_copy.iloc[:, :-1]\n",
    "    y_target = df_copy.iloc[:, -1]\n",
    "    # train_test_split()으로 학습과 테스트 데이터 분할. stratify=y_target으로 Stratified 기반 분할\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_features, y_target, test_size=0.3, random_state=0, stratify=y_target)\n",
    "    return X_train, X_test, y_train, y_test\n",
    "\n",
    "X_train, X_test, y_train, y_test = get_train_test_dataset(card_df)\n",
    "\n",
    "lr_clf = LogisticRegression()\n",
    "lr_clf.fit(X_train, y_train)\n",
    "lr_pred = lr_clf.predict(X_test)\n",
    "\n",
    "# 3장에서 사용한 get_clf_eval()함수를 이용해 평가 수행\n",
    "def get_clf_eval(y_test , pred):\n",
    "    confusion = confusion_matrix(y_test, pred)\n",
    "    accuracy = accuracy_score(y_test, pred)\n",
    "    precision = precision_score(y_test, pred)\n",
    "    recall = recall_score(y_test, pred)\n",
    "    f1 = f1_score(y_test, pred)\n",
    "    # ROC-AUC 추가\n",
    "    roc_auc = roc_auc_score(y_test, pred)\n",
    "    print('오차 행렬')\n",
    "    print(confusion)\n",
    "    # ROC-AUC print 추가\n",
    "    print('정확도: {0:.4f}, 정밀도: {1:.4f}, 재현율: {2:.4f},\\\n",
    "    F1: {3:.4f}, AUC:{4:.4f}'.format(accuracy, precision, recall, f1, roc_auc))\n",
    "\n",
    "\n",
    "get_clf_eval(y_test, lr_pred)\n",
    "\n",
    "# 인자로 사이킷런의 Estimator객체와 학습/테스트 데이터 세트를 입력 받아서 학습/예측/평가 수행.\n",
    "def get_model_train_eval(model, ftr_train=None, ftr_test=None, tgt_train=None, tgt_test=None):\n",
    "    model.fit(ftr_train, tgt_train)\n",
    "    pred = model.predict(ftr_test)\n",
    "    get_clf_eval(tgt_test, pred)\n",
    "\n",
    "lgbm_clf = LGBMClassifier(n_estimators=1000, num_leaves=64, n_jobs=1, boost_from_average=False)\n",
    "get_model_train_eval(lgbm_clf, ftr_train=X_train, ftr_test=X_test, tgt_train=y_train, tgt_test=y_test)\n",
    "\n",
    "\n",
    "# 데이터 분포도 변환 후 모델 학습/예측/평가\n",
    "plt.figure(figsize=(8,4))\n",
    "plt.xticks(range(0, 30000, 1000), rotation=60)\n",
    "sns.distplot(card_df['Amount'])\n",
    "plt.show()\n",
    "\n",
    "# 사이킷런의 StandardScaler를 이용해 정규 분포 형태로 Amount 피처값 변환하는 로직으로 수정.\n",
    "def get_preprocessed_df(df=None):\n",
    "    df_copy = df.copy()\n",
    "    scaler = StandardScaler()\n",
    "    amount_n = scaler.fit_transform(df_copy['Amount'].values.reshape(-1, 1))\n",
    "    # 변환된 Amount를 Amount_Scaled로 피처명 변경 후 DataFrame맨 앞 칼럼으로 입력\n",
    "    df_copy.insert(0, 'Amount_Scaled', amount_n)\n",
    "    # 기존 Time, Amount 피처 삭제\n",
    "    df_copy.drop(['Time', 'Amount'], axis=1, inplace=True)\n",
    "    return df_copy\n",
    "\n",
    "\n",
    "# Amount를 정규 분포 형태로 변환 후 로지스틱 회귀 및 lightGBM 수행.\n",
    "X_train, X_test, y_train, y_test = get_train_test_dataset(card_df)\n",
    "\n",
    "print('### 로지스틱 회귀 예측 성능 ###')\n",
    "lr_clf = LogisticRegression()\n",
    "get_model_train_eval(lr_clf, ftr_train=X_train, ftr_test=X_test, tgt_train=y_train,\n",
    "                     tgt_test=y_test)\n",
    "\n",
    "print('### LightGBM 예측 성능 ###')\n",
    "lgbm_clf = LGBMClassifier(n_estimators=1000, num_leaves=64, n_jobs=-1, boost_from_average=False)\n",
    "get_model_train_eval(lgbm_clf, ftr_train=X_train, ftr_test=X_test, tgt_train=y_train,\n",
    "                     tgt_test=y_test)\n",
    "\n",
    "# 로그 사용\n",
    "# : 데이터 분포도가 심하게 왜곡되어 있을 때 사용. 원래 값을 log 값으로 변환해 원래 큰 값을 상대적으로 작은 값으로 변환하기 때문에 왜곡을 상당 수준 개선해줌. numpy의 log1p() 함수 사용.\n",
    "def get_preprocessed_df(df=None):\n",
    "    df_copy = df.copy()\n",
    "    # 넘파이의 log1p( )를 이용하여 Amount를 로그 변환\n",
    "    amount_n = np.log1p(df_copy['Amount'])\n",
    "    df_copy.insert(0, 'Amount_Scaled', amount_n)\n",
    "    df_copy.drop(['Time','Amount'], axis=1, inplace=True)\n",
    "    return df_copy\n",
    "\n",
    "\n",
    "# 다시 로그 변환에 대한 예측 성능 평가\n",
    "X_train, X_test, y_train, y_test = get_train_test_dataset(card_df)\n",
    "\n",
    "print('### 로지스틱 회귀 예측 성능 ###')\n",
    "get_model_train_eval(lr_clf, ftr_train=X_train, ftr_test=X_test, tgt_train=y_train, tgt_test=y_test)\n",
    "\n",
    "print('### LightGBM 예측 성능 ###')\n",
    "get_model_train_eval(lgbm_clf, ftr_train=X_train, ftr_test=X_test, tgt_train=y_train, tgt_test=y_test)\n",
    "\n",
    "\n",
    "\n",
    "# 이상치 제거 후 평가\n",
    "import seaborn as sns\n",
    "plt.figure(figsize=(8,4))\n",
    "plt.xticks(range(0, 30000, 1000), rotation=60)\n",
    "sns.distplot(card_df['Amount'])\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "def get_outlier(df=None, column=None, weight=1.5):\n",
    "    # fraud에 해당하는 column 데이터만 추출, 1/4 분위와 3/4 분위 지점을 np.percentile로 구함.\n",
    "    fraud = df[df['Class']==1][column]\n",
    "    quantile_25 = np.percentile(fraud.values, 25)\n",
    "    quantile_75 = np.percentile(fraud.values, 75)\n",
    "    # IQR을 구하고, IQR에 1.5를 곱하여 최대값과 최소값 지점 구함.\n",
    "    iqr = quantile_75 - quantile_25\n",
    "    iqr_weight = iqr * weight\n",
    "    lowest_val = quantile_25 - iqr_weight\n",
    "    highest_val = quantile_75 + iqr_weight\n",
    "    # 최대값 보다 크거나, 최소값 보다 작은 값을 아웃라이어로 설정하고 DataFrame index 반환.\n",
    "    outlier_index = fraud[(fraud < lowest_val) | (fraud > highest_val)].index\n",
    "    return outlier_index\n",
    "\n",
    "outlier_index = get_outlier(df=card_df, column='V14', weight=1.5)\n",
    "print('이상치 데이터 인덱스:', outlier_index)\n",
    "\n",
    "# get_processed_df( )를 로그 변환 후 V14 피처의 이상치 데이터를 삭제하는 로직으로 변경.\n",
    "def get_preprocessed_df(df=None):\n",
    "    df_copy = df.copy()\n",
    "    amount_n = np.log1p(df_copy['Amount'])\n",
    "    df_copy.insert(0, 'Amount_Scaled', amount_n)\n",
    "    df_copy.drop(['Time','Amount'], axis=1, inplace=True)\n",
    "    # 이상치 데이터 삭제하는 로직 추가\n",
    "    outlier_index = get_outlier(df=df_copy, column='V14', weight=1.5)\n",
    "    df_copy.drop(outlier_index, axis=0, inplace=True)\n",
    "    return df_copy\n",
    "\n",
    "X_train, X_test, y_train, y_test = get_train_test_dataset(card_df)\n",
    "print('### 로지스틱 회귀 예측 성능 ###')\n",
    "get_model_train_eval(lr_clf, ftr_train=X_train, ftr_test=X_test, tgt_train=y_train, tgt_test=y_test)\n",
    "print('### LightGBM 예측 성능 ###')\n",
    "get_model_train_eval(lgbm_clf, ftr_train=X_train, ftr_test=X_test, tgt_train=y_train, tgt_test=y_test)\n",
    "\n",
    "\n",
    "# SMOTE Over Sampling\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "smote = SMOTE(random_state=0)\n",
    "X_train_over, y_train_over = smote.fit_sample(X_train, y_train)\n",
    "print('SMOTE 적용 전 학습용 피처/레이블 데이터 세트: ', X_train.shape, y_train.shape)\n",
    "print('SMOTE 적용 후 학습용 피처/레이블 데이터 세트: ', X_train_over.shape, y_train_over.shape)\n",
    "print('SMOTE 적용 후 레이블 값 분포: \\n', pd.Series(y_train_over).value_counts())\n",
    "\n",
    "lr_clf = LogisticRegression()\n",
    "# ftr_train과 tgt_train 인자값이 SMOTE 증식된 X_train_over와 y_train_over로 변경됨에 유의\n",
    "get_model_train_eval(lr_clf, ftr_train=X_train_over, ftr_test=X_test, tgt_train=y_train_over, tgt_test=y_test)\n",
    "\n",
    "# 결론 : 그래서 좋은 SMOTE 패키지 일수록 재현율 증가율은 높이고 정밀도 감소율은 줄인다.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
